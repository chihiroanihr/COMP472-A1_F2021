---------- GaussianNB() ----------
Result Prediction (Actual value & Predicted value):
(b) Confusion matrix: 
[[ 3  0  0  0  0]
 [ 0  3  0  0  0]
 [ 0  0  2  0  0]
 [ 0  0  0 13  0]
 [ 3  3  3  0 10]]
(c) Classification report (Precision, Recall, F1): 

              precision    recall  f1-score   support

           0       0.50      1.00      0.67         3
           1       0.50      1.00      0.67         3
           2       0.40      1.00      0.57         2
           3       1.00      1.00      1.00        13
           4       1.00      0.53      0.69        19

    accuracy                           0.78        40
   macro avg       0.68      0.91      0.72        40
weighted avg       0.89      0.78      0.78        40
(d) Accuracy score: 0.775 (77.5%)
    F1-score with macro average: 0.7189 (71.89%)
    F1-score with weighted average: 0.7812 (78.12%)


---------- DecisionTreeClassifier() ----------
Result Prediction (Actual value & Predicted value):
(b) Confusion matrix: 
[[ 3  0  0  0  0]
 [ 0  3  0  0  0]
 [ 0  0  2  0  0]
 [ 0  0  0 13  0]
 [ 0  0  0  0 19]]
(c) Classification report (Precision, Recall, F1): 

              precision    recall  f1-score   support

           0       1.00      1.00      1.00         3
           1       1.00      1.00      1.00         3
           2       1.00      1.00      1.00         2
           3       1.00      1.00      1.00        13
           4       1.00      1.00      1.00        19

    accuracy                           1.00        40
   macro avg       1.00      1.00      1.00        40
weighted avg       1.00      1.00      1.00        40
(d) Accuracy score: 1.0 (100.0%)
    F1-score with macro average: 1.0 (100.0%)
    F1-score with weighted average: 1.0 (100.0%)


---------- DecisionTreeClassifier(max_depth=6, min_samples_leaf=0.02) ----------
Best Parameter chosen for this classifier: {'criterion': 'gini', 'max_depth': 6, 'min_samples_leaf': 0.02}
Best score obtained from the chosen parameter: 0.9875
Result Prediction (Actual value & Predicted value):
(b) Confusion matrix: 
[[ 3  0  0  0  0]
 [ 0  3  0  0  0]
 [ 0  0  2  0  0]
 [ 0  0  0 13  0]
 [ 0  0  0  0 19]]
(c) Classification report (Precision, Recall, F1): 

              precision    recall  f1-score   support

           0       1.00      1.00      1.00         3
           1       1.00      1.00      1.00         3
           2       1.00      1.00      1.00         2
           3       1.00      1.00      1.00        13
           4       1.00      1.00      1.00        19

    accuracy                           1.00        40
   macro avg       1.00      1.00      1.00        40
weighted avg       1.00      1.00      1.00        40
(d) Accuracy score: 1.0 (100.0%)
    F1-score with macro average: 1.0 (100.0%)
    F1-score with weighted average: 1.0 (100.0%)


---------- Perceptron() ----------
Result Prediction (Actual value & Predicted value):
(b) Confusion matrix: 
[[ 0  0  0  3  0]
 [ 0  0  0  3  0]
 [ 0  0  0  2  0]
 [ 0  0  0 12  1]
 [ 0  0  0  9 10]]
(c) Classification report (Precision, Recall, F1): 

              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.00      0.00      0.00         3
           2       0.00      0.00      0.00         2
           3       0.41      0.92      0.57        13
           4       0.91      0.53      0.67        19

    accuracy                           0.55        40
   macro avg       0.26      0.29      0.25        40
weighted avg       0.57      0.55      0.50        40
(d) Accuracy score: 0.55 (55.0%)
    F1-score with macro average: 0.2476 (24.76%)
    F1-score with weighted average: 0.5024 (50.24%)


---------- MLPClassifier(activation='logistic', solver='sgd') ----------
Result Prediction (Actual value & Predicted value):
(b) Confusion matrix: 
[[ 0  0  0  1  2]
 [ 0  0  0  3  0]
 [ 0  0  0  1  1]
 [ 0  0  0  8  5]
 [ 0  0  0  1 18]]
(c) Classification report (Precision, Recall, F1): 

              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.00      0.00      0.00         3
           2       0.00      0.00      0.00         2
           3       0.57      0.62      0.59        13
           4       0.69      0.95      0.80        19

    accuracy                           0.65        40
   macro avg       0.25      0.31      0.28        40
weighted avg       0.51      0.65      0.57        40
(d) Accuracy score: 0.65 (65.0%)
    F1-score with macro average: 0.2785 (27.85%)
    F1-score with weighted average: 0.5726 (57.26%)


---------- MLPClassifier(activation='tanh', hidden_layer_sizes=(30, 50)) ----------
Best Parameter chosen for this classifier: {'activation': 'tanh', 'hidden_layer_sizes': (30, 50), 'solver': 'adam'}
Best score obtained from the chosen parameter: 0.825
Result Prediction (Actual value & Predicted value):
(b) Confusion matrix: 
[[ 2  1  0  0  0]
 [ 0  3  0  0  0]
 [ 0  0  2  0  0]
 [ 0  0  0 12  1]
 [ 0  0  0  0 19]]
(c) Classification report (Precision, Recall, F1): 

              precision    recall  f1-score   support

           0       1.00      0.67      0.80         3
           1       0.75      1.00      0.86         3
           2       1.00      1.00      1.00         2
           3       1.00      0.92      0.96        13
           4       0.95      1.00      0.97        19

    accuracy                           0.95        40
   macro avg       0.94      0.92      0.92        40
weighted avg       0.96      0.95      0.95        40
(d) Accuracy score: 0.95 (95.0%)
    F1-score with macro average: 0.9183 (91.83%)
    F1-score with weighted average: 0.9491 (94.91%)




================== Question (8) ==================

List of accuracy for each classifier types after 10 iterations: [[0.775, 1.0, 1.0, 0.55, 0.65, 0.9], [0.775, 1.0, 1.0, 0.55, 0.625, 0.8], [0.775, 1.0, 1.0, 0.55, 0.675, 0.875], [0.775, 1.0, 1.0, 0.55, 0.625, 0.8], [0.775, 1.0, 1.0, 0.55, 0.65, 0.875], [0.775, 1.0, 1.0, 0.55, 0.65, 0.825], [0.775, 1.0, 1.0, 0.55, 0.675, 0.95], [0.775, 1.0, 1.0, 0.55, 0.675, 0.825], [0.775, 1.0, 1.0, 0.55, 0.675, 0.9], [0.775, 1.0, 1.0, 0.55, 0.675, 0.8]]
Average accuracy for each classifier types after 10 iterations: [0.775, 1.0, 1.0, 0.55, 0.6575, 0.855]
Average total accuracy: 0.8062
Standard deviation of accuracy: 0.1664

List of f1 macro score for each classifier types after 10 iterations: [[0.7189, 1.0, 1.0, 0.2476, 0.2785, 0.8122], [0.7189, 1.0, 1.0, 0.2476, 0.2642, 0.6028], [0.7189, 1.0, 1.0, 0.2476, 0.2883, 0.6596], [0.7189, 1.0, 1.0, 0.2476, 0.2642, 0.5101], [0.7189, 1.0, 1.0, 0.2476, 0.2785, 0.813], [0.7189, 1.0, 1.0, 0.2476, 0.2779, 0.6448], [0.7189, 1.0, 1.0, 0.2476, 0.2883, 0.9183], [0.7189, 1.0, 1.0, 0.2476, 0.2883, 0.616], [0.7189, 1.0, 1.0, 0.2476, 0.2883, 0.7041], [0.7189, 1.0, 1.0, 0.2476, 0.2874, 0.5571]]
Average f1 macro score for each classifier types after 10 iterations: [0.7189, 1.0, 1.0, 0.2476, 0.2804, 0.6838]
Average total f1 macro score: 0.6551
Standard deviation of f1 macro score: 0.3026

List of f1 weighted score for each classifier types after 10 iterations: [[0.7812, 1.0, 1.0, 0.5024, 0.5726, 0.8976], [0.7812, 1.0, 1.0, 0.5024, 0.5467, 0.7804], [0.7812, 1.0, 1.0, 0.5024, 0.5924, 0.8514], [0.7812, 1.0, 1.0, 0.5024, 0.5467, 0.7524], [0.7812, 1.0, 1.0, 0.5024, 0.5726, 0.8636], [0.7812, 1.0, 1.0, 0.5024, 0.5744, 0.8018], [0.7812, 1.0, 1.0, 0.5024, 0.5924, 0.9491], [0.7812, 1.0, 1.0, 0.5024, 0.5924, 0.8055], [0.7812, 1.0, 1.0, 0.5024, 0.5924, 0.876], [0.7812, 1.0, 1.0, 0.5024, 0.5937, 0.7765]]
Average f1 weighted score for each classifier types after 10 iterations: [0.7812, 1.0, 1.0, 0.5024, 0.5776, 0.8354]
Average total f1 weighted score: 0.7828
Standard deviation of f1 weighted score: 0.1905

