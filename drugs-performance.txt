---------- GaussianNB() ----------
Result Prediction (Actual value & Predicted value):
(b) Confusion matrix: 
[[ 5  0  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  3  0  0]
 [ 0  0  0 13  1]
 [ 0  1  1  0 16]]
(c) Classification report (Precision, Recall, F1): 

              precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           1       0.00      0.00      0.00         0
           2       0.75      1.00      0.86         3
           3       1.00      0.93      0.96        14
           4       0.94      0.89      0.91        18

    accuracy                           0.93        40
   macro avg       0.74      0.76      0.75        40
weighted avg       0.95      0.93      0.94        40
(d) Accuracy score: 0.925 (92.5%)
    F1-score with macro average: 0.7469 (74.69%)
    F1-score with weighted average: 0.9378 (93.78%)


---------- DecisionTreeClassifier() ----------
Result Prediction (Actual value & Predicted value):
(b) Confusion matrix: 
[[ 5  0  0  0]
 [ 0  3  0  0]
 [ 0  0 13  1]
 [ 0  0  0 18]]
(c) Classification report (Precision, Recall, F1): 

              precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         3
           3       1.00      0.93      0.96        14
           4       0.95      1.00      0.97        18

    accuracy                           0.97        40
   macro avg       0.99      0.98      0.98        40
weighted avg       0.98      0.97      0.97        40
(d) Accuracy score: 0.975 (97.5%)
    F1-score with macro average: 0.984 (98.4%)
    F1-score with weighted average: 0.9749 (97.49%)


---------- DecisionTreeClassifier(max_depth=6, min_samples_leaf=0.02) ----------
Best Parameter chosen for this classifier: {'criterion': 'gini', 'max_depth': 6, 'min_samples_leaf': 0.02}
Best score obtained from the chosen parameter: 0.99375
Result Prediction (Actual value & Predicted value):
(b) Confusion matrix: 
[[ 5  0  0  0]
 [ 0  3  0  0]
 [ 0  0 13  1]
 [ 0  0  0 18]]
(c) Classification report (Precision, Recall, F1): 

              precision    recall  f1-score   support

           0       1.00      1.00      1.00         5
           2       1.00      1.00      1.00         3
           3       1.00      0.93      0.96        14
           4       0.95      1.00      0.97        18

    accuracy                           0.97        40
   macro avg       0.99      0.98      0.98        40
weighted avg       0.98      0.97      0.97        40
(d) Accuracy score: 0.975 (97.5%)
    F1-score with macro average: 0.984 (98.4%)
    F1-score with weighted average: 0.9749 (97.49%)


---------- Perceptron() ----------
Result Prediction (Actual value & Predicted value):
(b) Confusion matrix: 
[[ 0  0  2  3]
 [ 0  0  1  2]
 [ 0  0  4 10]
 [ 0  0  0 18]]
(c) Classification report (Precision, Recall, F1): 

              precision    recall  f1-score   support

           0       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         3
           3       0.57      0.29      0.38        14
           4       0.55      1.00      0.71        18

    accuracy                           0.55        40
   macro avg       0.28      0.32      0.27        40
weighted avg       0.45      0.55      0.45        40
(d) Accuracy score: 0.55 (55.0%)
    F1-score with macro average: 0.2717 (27.17%)
    F1-score with weighted average: 0.451 (45.1%)


---------- MLPClassifier(activation='logistic', solver='sgd') ----------
Result Prediction (Actual value & Predicted value):
(b) Confusion matrix: 
[[ 0  0  2  3]
 [ 0  0  1  2]
 [ 0  0  8  6]
 [ 0  0  0 18]]
(c) Classification report (Precision, Recall, F1): 

              precision    recall  f1-score   support

           0       0.00      0.00      0.00         5
           2       0.00      0.00      0.00         3
           3       0.73      0.57      0.64        14
           4       0.62      1.00      0.77        18

    accuracy                           0.65        40
   macro avg       0.34      0.39      0.35        40
weighted avg       0.53      0.65      0.57        40
(d) Accuracy score: 0.65 (65.0%)
    F1-score with macro average: 0.3515 (35.15%)
    F1-score with weighted average: 0.5687 (56.87%)


---------- MLPClassifier(activation='tanh', hidden_layer_sizes=(30, 50)) ----------
Best Parameter chosen for this classifier: {'activation': 'tanh', 'hidden_layer_sizes': (30, 50), 'solver': 'adam'}
Best score obtained from the chosen parameter: 0.825
Result Prediction (Actual value & Predicted value):
(b) Confusion matrix: 
[[ 4  1  0  0  0]
 [ 0  0  0  0  0]
 [ 0  0  0  1  2]
 [ 0  0  0 14  0]
 [ 0  0  0  0 18]]
(c) Classification report (Precision, Recall, F1): 

              precision    recall  f1-score   support

           0       1.00      0.80      0.89         5
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         3
           3       0.93      1.00      0.97        14
           4       0.90      1.00      0.95        18

    accuracy                           0.90        40
   macro avg       0.57      0.56      0.56        40
weighted avg       0.86      0.90      0.88        40
(d) Accuracy score: 0.9 (90.0%)
    F1-score with macro average: 0.5604 (56.04%)
    F1-score with weighted average: 0.8754 (87.54%)




================== Question (8) ==================

List of accuracy after 10 iterations for each classes: [0.925, 0.975, 0.975, 0.55, 0.5675, 0.875]
Average accuracy: 0.8112
Standard deviation of accuracy: 0.1818

List of f1 macro score after 10 iterations for each classes: [0.7469, 0.984, 0.984, 0.2717, 0.2865, 0.5837]
Average f1 macro score: 0.6428
Standard deviation of f1 macro score: 0.2921

List of f1 weighted score after 10 iterations for each classes: [0.9378, 0.9749, 0.9749, 0.451, 0.4724, 0.8623]
Average f1 weighted score: 0.7789
Standard deviation of f1 weighted score: 0.2275

